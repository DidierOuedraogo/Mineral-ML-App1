import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, r2_score, mean_absolute_error, mean_squared_error
)
from sklearn.preprocessing import StandardScaler
import io

# Configuration de la page
st.set_page_config(
    page_title="Application ML Mining - Didier Ouedraogo",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ======================= AUTHENTIFICATION ======================= #
def check_login(username, password):
    """V√©rifie les identifiants de connexion"""
    users = {
        "Didier": "Gloria",
        "student": "E3MG25"
    }
    return users.get(username) == password

# Initialisation de la session
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False
if 'username' not in st.session_state:
    st.session_state.username = ""

# Page de connexion
if not st.session_state.logged_in:
    st.markdown("""
    <style>
        .login-header {
            background: linear-gradient(90deg, #4b5563 0%, #374151 100%);
            padding: 3rem;
            border-radius: 15px;
            color: white;
            text-align: center;
            margin-bottom: 2rem;
            box-shadow: 0 10px 25px rgba(0,0,0,0.2);
        }
        .login-box {
            background: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 10px 25px rgba(0,0,0,0.1);
            border: 2px solid #e5e7eb;
        }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="login-header">
        <h1>üéØ Application Machine Learning P√©dagogique</h1>
        <h2>Pour l'Industrie Mini√®re</h2>
        <p style="font-size: 1.1rem; margin-top: 1rem;">Auteur: Didier Ouedraogo, P.Geo</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown('<div class="login-box">', unsafe_allow_html=True)
        st.markdown("### üîê Authentification")
        st.markdown("---")
        
        with st.form("login_form"):
            username = st.text_input("üë§ Nom d'utilisateur", key="login_username")
            password = st.text_input("üîí Mot de passe", type="password", key="login_password")
            
            col_btn1, col_btn2, col_btn3 = st.columns([1, 2, 1])
            with col_btn2:
                submit = st.form_submit_button("üîì Se connecter", use_container_width=True)
            
            if submit:
                if check_login(username, password):
                    st.session_state.logged_in = True
                    st.session_state.username = username
                    st.success("‚úÖ Connexion r√©ussie!")
                    st.rerun()
                else:
                    st.error("‚ùå Nom d'utilisateur ou mot de passe incorrect")
        
        st.markdown("---")
        st.info("""
        **üìã Comptes de test disponibles:**
        
        - **Compte 1:** Didier / Gloria
        - **Compte 2:** student / E3MG25
        """)
        st.markdown('</div>', unsafe_allow_html=True)
    
    st.stop()

# ======================= APPLICATION PRINCIPALE ======================= #

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #4b5563 0%, #374151 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        border-left: 4px solid #8b5cf6;
    }
    .step-header {
        background: linear-gradient(90deg, #8b5cf6 0%, #6366f1 100%);
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        font-weight: 600;
    }
    .info-box {
        background: #dbeafe;
        border-left: 4px solid #3b82f6;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .success-box {
        background: #d1fae5;
        border-left: 4px solid #10b981;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .warning-box {
        background: #fef3c7;
        border-left: 4px solid #f59e0b;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #1f2937;
        color: #d1d5db;
        border-radius: 8px 8px 0 0;
        padding: 10px 20px;
        font-weight: 600;
    }
    .stTabs [aria-selected="true"] {
        background: linear-gradient(90deg, #8b5cf6 0%, #6366f1 100%);
        color: white;
    }
    div[data-testid="stExpander"] {
        background-color: #f9fafb;
        border: 2px solid #e5e7eb;
        border-radius: 8px;
    }
    .footer {
        background: #4b5563;
        color: white;
        text-align: center;
        padding: 1rem;
        margin-top: 3rem;
        border-radius: 8px;
    }
    .user-badge {
        background: linear-gradient(90deg, #8b5cf6 0%, #6366f1 100%);
        color: white;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-weight: 600;
        text-align: center;
        margin-bottom: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# Sidebar avec informations utilisateur
st.sidebar.markdown(f'<div class="user-badge">üë§ {st.session_state.username}</div>', unsafe_allow_html=True)
st.sidebar.markdown("---")

if st.sidebar.button("üö™ D√©connexion", use_container_width=True):
    st.session_state.logged_in = False
    st.session_state.username = ""
    st.rerun()

st.sidebar.markdown("---")
st.sidebar.markdown("### üìä Navigation")
st.sidebar.info("Plateforme d'apprentissage du Machine Learning appliqu√© √† l'industrie mini√®re")

# En-t√™te principal
st.markdown(f"""
<div class="main-header">
    <h1>üéØ Application Machine Learning P√©dagogique</h1>
    <h2>Pour l'Industrie Mini√®re</h2>
    <p>Auteur: Didier Ouedraogo, P.Geo | Exp√©rimentez avec des algorithmes ML appliqu√©s au secteur minier</p>
    <p style="margin-top: 0.5rem; font-size: 0.9rem; opacity: 0.9;">Connect√© en tant que: <strong>{st.session_state.username}</strong></p>
</div>
""", unsafe_allow_html=True)

# Fonction pour t√©l√©charger les donn√©es
def download_data(df, filename):
    csv = df.to_csv(index=False)
    return csv

# Initialisation des variables de session
if 'classif_data' not in st.session_state:
    st.session_state.classif_data = None
if 'reg_data' not in st.session_state:
    st.session_state.reg_data = None
if 'optim_data' not in st.session_state:
    st.session_state.optim_data = None
if 'maint_data' not in st.session_state:
    st.session_state.maint_data = None

# Onglets principaux
tab1, tab2, tab3, tab4 = st.tabs([
    "üî¨ Classification Minerai",
    "üìà R√©gression Teneurs",
    "‚öôÔ∏è Optimisation Process",
    "üîß Maintenance Pr√©dictive"
])

# ======================= ONGLET 1: CLASSIFICATION ======================= #
with tab1:
    st.markdown("## Classification de Minerai: R√©fractaire vs Non-R√©fractaire")
    
    st.markdown("""
    <div class="info-box">
        <strong>üéØ Objectif:</strong><br>
        Classifier automatiquement le minerai aurif√®re en deux cat√©gories (R√©fractaire / Non-R√©fractaire) 
        √† partir d'analyses g√©ochimiques et min√©ralogiques pour optimiser le choix du traitement m√©tallurgique.
    </div>
    """, unsafe_allow_html=True)
    
    # √âTAPE 1: G√©n√©ration des donn√©es
    st.markdown('<div class="step-header">üìä √âtape 1: G√©n√©ration des Donn√©es</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### Param√®tres de G√©n√©ration")
        classif_samples = st.slider("Nombre d'√©chantillons", 100, 5000, 1000, 100)
        classif_prop = st.slider("Proportion R√©fractaire (%)", 20, 60, 40, 5)
        classif_noise = st.slider("Bruit dans les donn√©es (%)", 0, 50, 10, 5)
        
        if st.button("üé≤ G√©n√©rer les Donn√©es", key="gen_classif"):
            # G√©n√©ration des donn√©es
            n_refract = int(classif_samples * classif_prop / 100)
            n_non_refract = classif_samples - n_refract
            noise_factor = classif_noise / 100
            
            data = []
            
            # Minerai R√©fractaire
            for i in range(n_refract):
                pyrite = 8 + np.random.random() * 12 + (np.random.random() - 0.5) * noise_factor * 10
                arsenopyrite = 3 + np.random.random() * 7 + (np.random.random() - 0.5) * noise_factor * 5
                carbone = 0.8 + np.random.random() * 2.5 + (np.random.random() - 0.5) * noise_factor * 2
                oxydation = 10 + np.random.random() * 30 + (np.random.random() - 0.5) * noise_factor * 20
                taille_grain = 2 + np.random.random() * 15 + (np.random.random() - 0.5) * noise_factor * 10
                sulfures_totaux = pyrite + arsenopyrite + np.random.random() * 5
                antimoine = 200 + np.random.random() * 800 + (np.random.random() - 0.5) * noise_factor * 400
                recup_grav = 5 + np.random.random() * 25 + (np.random.random() - 0.5) * noise_factor * 15
                
                data.append({
                    'Pyrite_%': round(pyrite, 2),
                    'Arsenopyrite_%': round(arsenopyrite, 2),
                    'Carbone_org_%': round(carbone, 2),
                    'Oxydation': round(oxydation, 1),
                    'Taille_grain_um': round(taille_grain, 1),
                    'Sulfures_totaux_%': round(sulfures_totaux, 2),
                    'Antimoine_ppm': round(antimoine, 0),
                    'Recup_grav_%': round(recup_grav, 1),
                    'Classe': 'R√©fractaire'
                })
            
            # Minerai Non-R√©fractaire
            for i in range(n_non_refract):
                pyrite = 0.5 + np.random.random() * 4 + (np.random.random() - 0.5) * noise_factor * 3
                arsenopyrite = 0.1 + np.random.random() * 1.5 + (np.random.random() - 0.5) * noise_factor * 1
                carbone = 0.05 + np.random.random() * 0.5 + (np.random.random() - 0.5) * noise_factor * 0.3
                oxydation = 60 + np.random.random() * 35 + (np.random.random() - 0.5) * noise_factor * 20
                taille_grain = 30 + np.random.random() * 100 + (np.random.random() - 0.5) * noise_factor * 50
                sulfures_totaux = pyrite + arsenopyrite + np.random.random() * 2
                antimoine = 10 + np.random.random() * 150 + (np.random.random() - 0.5) * noise_factor * 100
                recup_grav = 55 + np.random.random() * 40 + (np.random.random() - 0.5) * noise_factor * 20
                
                data.append({
                    'Pyrite_%': round(pyrite, 2),
                    'Arsenopyrite_%': round(arsenopyrite, 2),
                    'Carbone_org_%': round(carbone, 2),
                    'Oxydation': round(oxydation, 1),
                    'Taille_grain_um': round(taille_grain, 1),
                    'Sulfures_totaux_%': round(sulfures_totaux, 2),
                    'Antimoine_ppm': round(antimoine, 0),
                    'Recup_grav_%': round(recup_grav, 1),
                    'Classe': 'Non-R√©fractaire'
                })
            
            df = pd.DataFrame(data)
            df = df.sample(frac=1).reset_index(drop=True)
            st.session_state.classif_data = df
            st.success(f"‚úÖ {classif_samples} √©chantillons g√©n√©r√©s avec succ√®s!")
    
    with col2:
        st.markdown("### Variables Pr√©dictives")
        st.markdown("""
        <div style="background: #fee2e2; padding: 0.75rem; border-radius: 0.5rem; margin-bottom: 0.5rem; border-left: 4px solid #ef4444;">
            <strong style="color: #991b1b;">üî¥ Minerai R√©fractaire</strong><br>
            <small>Sulfures √©lev√©s, carbone organique, encapsulation Au</small>
        </div>
        <div style="background: #d1fae5; padding: 0.75rem; border-radius: 0.5rem; margin-bottom: 1rem; border-left: 4px solid #10b981;">
            <strong style="color: #065f46;">üü¢ Minerai Non-R√©fractaire</strong><br>
            <small>Or libre, oxydation √©lev√©e, cyanuration facile</small>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        **Variables utilis√©es:**
        - üîπ Pyrite (%) - Sulfure principal
        - üîπ Ars√©nopyrite (%) - Min√©ral r√©fractaire
        - üîπ Carbone organique (%) - Preg-robbing
        - üîπ Degr√© d'oxydation - √âtat min√©raux
        - üîπ Taille grain Au (Œºm) - Encapsulation
        - üîπ Sulfures totaux (%) - S total
        - üîπ Antimoine (ppm) - √âl√©ment d√©l√©t√®re
        - üîπ R√©cup√©ration gravim√©trique (%) - Or libre
        """)
    
    # Affichage des donn√©es g√©n√©r√©es
    if st.session_state.classif_data is not None:
        st.markdown("### üìä Aper√ßu des Donn√©es G√©n√©r√©es")
        
        col1, col2, col3 = st.columns(3)
        refract_count = len(st.session_state.classif_data[st.session_state.classif_data['Classe'] == 'R√©fractaire'])
        non_refract_count = len(st.session_state.classif_data[st.session_state.classif_data['Classe'] == 'Non-R√©fractaire'])
        
        col1.metric("Total √âchantillons", len(st.session_state.classif_data))
        col2.metric("R√©fractaire", refract_count)
        col3.metric("Non-R√©fractaire", non_refract_count)
        
        st.dataframe(st.session_state.classif_data.head(10), use_container_width=True)
        
        # T√©l√©chargement
        csv = download_data(st.session_state.classif_data, "classification_minerai.csv")
        st.download_button(
            label="üì• T√©l√©charger CSV",
            data=csv,
            file_name="classification_minerai.csv",
            mime="text/csv"
        )
    
    # √âTAPE 2: Configuration du mod√®le
    if st.session_state.classif_data is not None:
        st.markdown('<div class="step-header">‚öôÔ∏è √âtape 2: Configuration du Mod√®le</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            classif_algo = st.selectbox(
                "Algorithme de Classification",
                ["Random Forest", "SVM", "XGBoost", "Logistic Regression"],
                key="classif_algo_select"
            )
            
            algo_info = {
                "Random Forest": "Ensemble d'arbres de d√©cision - Robuste et pr√©cis",
                "SVM": "S√©paration par hyperplan - Donn√©es complexes",
                "XGBoost": "Boosting par gradient - Performance optimale",
                "Logistic Regression": "R√©gression logistique - Simple et interpr√©table"
            }
            st.info(algo_info[classif_algo])
        
        with col2:
            st.markdown("### Param√®tres du Mod√®le")
            
            if classif_algo == "Random Forest":
                col_a, col_b = st.columns(2)
                with col_a:
                    n_estimators = st.number_input("n_estimators", 10, 1000, 200, 10)
                    st.caption("Plus d'arbres = meilleure performance mais calcul plus lent")
                with col_b:
                    max_depth = st.number_input("max_depth", 3, 50, 15)
                    st.caption("Profondeur maximale. Trop √©lev√© = surapprentissage")
                min_samples = st.number_input("min_samples_split", 2, 20, 5)
                st.caption("Nombre minimum pour diviser un noeud")
                
            elif classif_algo == "SVM":
                col_a, col_b = st.columns(2)
                with col_a:
                    C = st.number_input("C (R√©gularisation)", 0.01, 100.0, 1.0, 0.1)
                    st.caption("Compromis entre marge maximale et erreurs")
                with col_b:
                    kernel = st.selectbox("kernel", ["rbf", "linear", "poly"])
                    st.caption("RBF: donn√©es non-lin√©aires")
                    
            elif classif_algo == "XGBoost":
                col_a, col_b = st.columns(2)
                with col_a:
                    n_estimators = st.number_input("n_estimators", 10, 1000, 100, 10)
                    st.caption("Nombre d'arbres de boosting")
                with col_b:
                    learning_rate = st.number_input("learning_rate", 0.01, 1.0, 0.1, 0.01)
                    st.caption("Contribution de chaque arbre")
                max_depth = st.number_input("max_depth", 3, 20, 6)
                st.caption("Profondeur max des arbres")
                
            else:  # Logistic Regression
                col_a, col_b = st.columns(2)
                with col_a:
                    C = st.number_input("C (Inverse r√©gularisation)", 0.001, 100.0, 1.0, 0.1)
                    st.caption("Plus petit C = r√©gularisation plus forte")
                with col_b:
                    max_iter = st.number_input("max_iter", 50, 1000, 100)
                    st.caption("Nombre max d'it√©rations")
        
        # √âTAPE 3: Entra√Ænement et r√©sultats
        st.markdown('<div class="step-header">üìä √âtape 3: R√©sultats et M√©triques</div>', unsafe_allow_html=True)
        
        if st.button("‚ñ∂ Entra√Æner le Mod√®le", key="train_classif"):
            with st.spinner("‚è≥ Entra√Ænement en cours..."):
                df = st.session_state.classif_data
                
                # Pr√©paration des donn√©es
                X = df.drop('Classe', axis=1)
                y = df['Classe'].map({'R√©fractaire': 1, 'Non-R√©fractaire': 0})
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, stratify=y, random_state=42
                )
                
                # Standardisation
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                
                # Entra√Ænement du mod√®le
                if classif_algo == "Random Forest":
                    model = RandomForestClassifier(
                        n_estimators=n_estimators,
                        max_depth=max_depth,
                        min_samples_split=min_samples,
                        class_weight='balanced',
                        random_state=42
                    )
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    
                elif classif_algo == "SVM":
                    model = SVC(C=C, kernel=kernel, class_weight='balanced', random_state=42)
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                    
                elif classif_algo == "XGBoost":
                    from xgboost import XGBClassifier
                    model = XGBClassifier(
                        n_estimators=n_estimators,
                        learning_rate=learning_rate,
                        max_depth=max_depth,
                        random_state=42
                    )
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    
                else:  # Logistic Regression
                    model = LogisticRegression(C=C, max_iter=max_iter, class_weight='balanced', random_state=42)
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                
                # Calcul des m√©triques
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred)
                recall = recall_score(y_test, y_pred)
                f1 = f1_score(y_test, y_pred)
                cm = confusion_matrix(y_test, y_pred)
                
                # Affichage des r√©sultats
                st.markdown("### üéØ M√©triques de Performance")
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("Accuracy", f"{accuracy:.3f}", f"{accuracy*100:.1f}%")
                col2.metric("Precision", f"{precision:.3f}", "Vrais + / Total +")
                col3.metric("Recall", f"{recall:.3f}", "Vrais + / R√©els +")
                col4.metric("F1-Score", f"{f1:.3f}", "Moyenne P & R")
                
                # Matrice de confusion
                st.markdown("### üìä Matrice de Confusion")
                
                fig = go.Figure(data=go.Heatmap(
                    z=cm,
                    x=['Non-R√©fractaire', 'R√©fractaire'],
                    y=['Non-R√©fractaire', 'R√©fractaire'],
                    text=cm,
                    texttemplate="%{text}",
                    textfont={"size": 20},
                    colorscale='Blues'
                ))
                fig.update_layout(
                    title="Matrice de Confusion",
                    xaxis_title="Pr√©diction",
                    yaxis_title="R√©alit√©",
                    height=400
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Interpr√©tation
                st.markdown(f"""
                <div class="info-box">
                    <strong>üí° Interpr√©tation:</strong><br>
                    ‚Ä¢ <strong>Accuracy = {accuracy*100:.1f}%:</strong> Identifie correctement le type dans {accuracy*100:.1f}% des cas<br>
                    ‚Ä¢ <strong>Recall = {recall*100:.1f}%:</strong> {recall*100:.1f}% des minerais r√©fractaires sont identifi√©s<br>
                    ‚Ä¢ <strong>Impact:</strong> √âvite co√ªts traitement inadapt√© et pertes m√©tallurgiques
                </div>
                """, unsafe_allow_html=True)
                
                # Importance des features (pour Random Forest et XGBoost)
                if classif_algo in ["Random Forest", "XGBoost"]:
                    st.markdown("### üìä Importance des Variables")
                    
                    feature_importance = pd.DataFrame({
                        'Feature': X.columns,
                        'Importance': model.feature_importances_
                    }).sort_values('Importance', ascending=True)
                    
                    fig = px.bar(
                        feature_importance,
                        x='Importance',
                        y='Feature',
                        orientation='h',
                        title="Importance des Variables dans la Classification"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # Code Python √©quivalent
                st.markdown("### üíª Code Python √âquivalent")
                
                code_map = {
                    "Random Forest": f"RandomForestClassifier(n_estimators={n_estimators}, max_depth={max_depth}, min_samples_split={min_samples})",
                    "SVM": f"SVC(C={C}, kernel='{kernel}')",
                    "XGBoost": f"XGBClassifier(n_estimators={n_estimators}, learning_rate={learning_rate}, max_depth={max_depth})",
                    "Logistic Regression": f"LogisticRegression(C={C}, max_iter={max_iter})"
                }
                
                code = f"""
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

model = {code_map[classif_algo]}
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(f"Accuracy: {accuracy:.3f}")
print(f"F1-Score: {f1:.3f}")
"""
                st.code(code, language="python")

# ======================= ONGLET 2: R√âGRESSION ======================= #
with tab2:
    st.markdown("## Pr√©diction des Teneurs en Or (g/t)")
    
    st.markdown("""
    <div class="info-box">
        <strong>üéØ Objectif:</strong><br>
        Pr√©dire la teneur en or √† partir de donn√©es g√©ochimiques (As, Cu, Sb) et g√©ospatiales 
        (distance √† faille, profondeur) en utilisant des algorithmes de r√©gression.
    </div>
    """, unsafe_allow_html=True)
    
    # √âTAPE 1: G√©n√©ration des donn√©es
    st.markdown('<div class="step-header">üìä √âtape 1: G√©n√©ration des Donn√©es</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### Param√®tres de G√©n√©ration")
        reg_samples = st.slider("Nombre d'√©chantillons", 100, 5000, 800, 100, key="reg_samples")
        reg_complexity = st.select_slider(
            "Complexit√© des relations",
            options=["Faible", "Moyenne", "√âlev√©e"],
            value="Moyenne",
            key="reg_complexity"
        )
        
        if st.button("üé≤ G√©n√©rer les Donn√©es", key="gen_reg"):
            complexity_map = {"Faible": 0.5, "Moyenne": 1.0, "√âlev√©e": 1.5}
            c_factor = complexity_map[reg_complexity]
            
            data = []
            for i in range(reg_samples):
                As = np.random.random() * 200 + 50
                Cu = np.random.random() * 500 + 100
                Sb = np.random.random() * 100 + 10
                dist_faille = np.random.random() * 500
                profondeur = np.random.random() * 300 + 50
                alteration = np.random.random() * 10
                
                # Mod√®le de teneur avec relations complexes
                teneur = (
                    0.5 +
                    (As / 100) * 0.3 * c_factor +
                    (Cu / 200) * 0.2 * c_factor +
                    (Sb / 50) * 0.25 * c_factor -
                    (dist_faille / 200) * 0.4 * c_factor +
                    (alteration / 10) * 0.5 * c_factor +
                    (np.random.random() - 0.5) * 0.8
                )
                teneur = max(0.1, min(10, teneur))
                
                data.append({
                    'As_ppm': round(As, 1),
                    'Cu_ppm': round(Cu, 1),
                    'Sb_ppm': round(Sb, 1),
                    'Dist_faille_m': round(dist_faille, 1),
                    'Profondeur_m': round(profondeur, 1),
                    'Alteration': round(alteration, 2),
                    'Teneur_Au_g_t': round(teneur, 3)
                })
            
            df = pd.DataFrame(data)
            st.session_state.reg_data = df
            st.success(f"‚úÖ {reg_samples} √©chantillons g√©n√©r√©s avec succ√®s!")
    
    with col2:
        st.markdown("### Variables Pr√©dictives")
        st.markdown("""
        **Variables utilis√©es:**
        - üîπ **Teneur Arsenic (As)** - √âl√©ment pathfinder pour l'or
        - üîπ **Teneur Cuivre (Cu)** - Associ√© aux min√©ralisations
        - üîπ **Teneur Antimoine (Sb)** - Indicateur hydrothermal
        - üîπ **Distance √† faille (m)** - Contr√¥le structural
        - üîπ **Profondeur (m)** - Niveau hydrothermal
        - üîπ **Index d'alt√©ration** - Intensit√© alt√©ration
        
        ‚ûú **Variable cible:** Teneur Au (g/t)
        """)
    
    # Affichage des donn√©es g√©n√©r√©es
    if st.session_state.reg_data is not None:
        st.markdown("### üìä Aper√ßu des Donn√©es G√©n√©r√©es")
        
        col1, col2, col3 = st.columns(3)
        avg_teneur = st.session_state.reg_data['Teneur_Au_g_t'].mean()
        max_teneur = st.session_state.reg_data['Teneur_Au_g_t'].max()
        min_teneur = st.session_state.reg_data['Teneur_Au_g_t'].min()
        
        col1.metric("Moy Au (g/t)", f"{avg_teneur:.3f}")
        col2.metric("Max Au (g/t)", f"{max_teneur:.3f}")
        col3.metric("Min Au (g/t)", f"{min_teneur:.3f}")
        
        st.dataframe(st.session_state.reg_data.head(10), use_container_width=True)
        
        # T√©l√©chargement
        csv = download_data(st.session_state.reg_data, "regression_teneurs.csv")
        st.download_button(
            label="üì• T√©l√©charger CSV",
            data=csv,
            file_name="regression_teneurs.csv",
            mime="text/csv",
            key="download_reg"
        )
        
        # Visualisation de la distribution
        fig = px.histogram(
            st.session_state.reg_data,
            x='Teneur_Au_g_t',
            nbins=50,
            title="Distribution des Teneurs en Or"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # √âTAPE 2: Configuration du mod√®le
    if st.session_state.reg_data is not None:
        st.markdown('<div class="step-header">‚öôÔ∏è √âtape 2: Configuration du Mod√®le</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            reg_algo = st.selectbox(
                "Algorithme de R√©gression",
                ["Random Forest", "Gradient Boosting", "Linear Regression"],
                key="reg_algo_select"
            )
            
            algo_info = {
                "Random Forest": "Moyenne d'arbres - Robuste aux outliers",
                "Gradient Boosting": "Optimisation s√©quentielle - Tr√®s performant",
                "Linear Regression": "R√©gression lin√©aire - Simple et rapide"
            }
            st.info(algo_info[reg_algo])
        
        with col2:
            st.markdown("### Param√®tres du Mod√®le")
            
            if reg_algo == "Random Forest":
                col_a, col_b = st.columns(2)
                with col_a:
                    n_estimators_reg = st.number_input("n_estimators", 10, 1000, 200, 10, key="rf_reg_n")
                    st.caption("Nombre d'arbres. Plus = pr√©dictions stables")
                with col_b:
                    max_depth_reg = st.number_input("max_depth", 3, 50, 12, key="rf_reg_depth")
                    st.caption("Profondeur maximale")
                min_samples_reg = st.number_input("min_samples_leaf", 1, 20, 2, key="rf_reg_samples")
                st.caption("Minimum d'√©chantillons dans feuille")
                
            elif reg_algo == "Gradient Boosting":
                col_a, col_b = st.columns(2)
                with col_a:
                    n_estimators_reg = st.number_input("n_estimators", 10, 1000, 300, 10, key="gb_reg_n")
                    st.caption("Nombre d'√©tapes de boosting")
                with col_b:
                    learning_rate_reg = st.number_input("learning_rate", 0.001, 1.0, 0.05, 0.01, key="gb_reg_lr")
                    st.caption("Pond√©ration de chaque arbre")
                max_depth_reg = st.number_input("max_depth", 3, 20, 8, key="gb_reg_depth")
                st.caption("Profondeur des arbres")
                
            else:  # Linear Regression
                fit_intercept = st.checkbox("fit_intercept", value=True, key="lr_intercept")
                st.caption("Calculer l'ordonn√©e √† l'origine")
        
        # √âTAPE 3: Entra√Ænement et r√©sultats
        st.markdown('<div class="step-header">üìä √âtape 3: R√©sultats et M√©triques</div>', unsafe_allow_html=True)
        
        if st.button("‚ñ∂ Entra√Æner le Mod√®le", key="train_reg"):
            with st.spinner("‚è≥ Entra√Ænement en cours..."):
                df = st.session_state.reg_data
                
                # Pr√©paration des donn√©es
                X = df.drop('Teneur_Au_g_t', axis=1)
                y = df['Teneur_Au_g_t']
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
                
                # Standardisation
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                
                # Entra√Ænement du mod√®le
                if reg_algo == "Random Forest":
                    model = RandomForestRegressor(
                        n_estimators=n_estimators_reg,
                        max_depth=max_depth_reg,
                        min_samples_leaf=min_samples_reg,
                        random_state=42
                    )
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    
                elif reg_algo == "Gradient Boosting":
                    model = GradientBoostingRegressor(
                        n_estimators=n_estimators_reg,
                        learning_rate=learning_rate_reg,
                        max_depth=max_depth_reg,
                        random_state=42
                    )
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    
                else:  # Linear Regression
                    model = LinearRegression(fit_intercept=fit_intercept)
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                
                # Calcul des m√©triques
                r2 = r2_score(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
                
                # Affichage des r√©sultats
                st.markdown("### üéØ M√©triques de Performance")
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("R¬≤ Score", f"{r2:.3f}", "Variance expliqu√©e")
                col2.metric("MAE", f"{mae:.3f} g/t", "Erreur absolue")
                col3.metric("RMSE", f"{rmse:.3f} g/t", "Erreur quadratique")
                col4.metric("MAPE", f"{mape:.1f}%", "Erreur % moyenne")
                
                # Interpr√©tation
                st.markdown(f"""
                <div class="info-box">
                    <strong>üí° Interpr√©tation:</strong><br>
                    ‚Ä¢ <strong>R¬≤ = {r2:.3f}:</strong> Le mod√®le explique {r2*100:.1f}% de la variance<br>
                    ‚Ä¢ <strong>MAE = {mae:.3f} g/t:</strong> Erreur moyenne absolue<br>
                    ‚Ä¢ <strong>RMSE = {rmse:.3f} g/t:</strong> P√©nalise grandes erreurs
                </div>
                """, unsafe_allow_html=True)
                
                # Graphique Pr√©dictions vs R√©alit√©
                st.markdown("### üìä Pr√©dictions vs R√©alit√©")
                
                results_df = pd.DataFrame({
                    'R√©el': y_test,
                    'Pr√©dit': y_pred
                })
                
                fig = px.scatter(
                    results_df,
                    x='R√©el',
                    y='Pr√©dit',
                    title="Teneurs Pr√©dites vs Teneurs R√©elles",
                    labels={'R√©el': 'Teneur R√©elle (g/t)', 'Pr√©dit': 'Teneur Pr√©dite (g/t)'}
                )
                
                # Ligne parfaite
                max_val = max(y_test.max(), y_pred.max())
                fig.add_trace(go.Scatter(
                    x=[0, max_val],
                    y=[0, max_val],
                    mode='lines',
                    name='Pr√©diction parfaite',
                    line=dict(color='red', dash='dash')
                ))
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Importance des features
                if reg_algo in ["Random Forest", "Gradient Boosting"]:
                    st.markdown("### üìä Importance des Variables")
                    
                    feature_importance = pd.DataFrame({
                        'Feature': X.columns,
                        'Importance': model.feature_importances_
                    }).sort_values('Importance', ascending=True)
                    
                    fig = px.bar(
                        feature_importance,
                        x='Importance',
                        y='Feature',
                        orientation='h',
                        title="Importance des Variables dans la Pr√©diction"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # Code Python √©quivalent
                st.markdown("### üíª Code Python √âquivalent")
                
                if reg_algo == "Random Forest":
                    params = f"n_estimators={n_estimators_reg}, max_depth={max_depth_reg}, min_samples_leaf={min_samples_reg}"
                    model_name = "RandomForestRegressor"
                elif reg_algo == "Gradient Boosting":
                    params = f"n_estimators={n_estimators_reg}, learning_rate={learning_rate_reg}, max_depth={max_depth_reg}"
                    model_name = "GradientBoostingRegressor"
                else:
                    params = f"fit_intercept={fit_intercept}"
                    model_name = "LinearRegression"
                
                code = f"""
from sklearn.ensemble import {model_name}
from sklearn.metrics import r2_score, mean_absolute_error

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = {model_name}({params})
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(f"R¬≤: {r2:.3f}")
print(f"MAE: {mae:.3f} g/t")
"""
                st.code(code, language="python")

# ======================= ONGLET 3: OPTIMISATION ======================= #
with tab3:
    st.markdown("## Optimisation du Process M√©tallurgique")
    
    st.markdown("""
    <div class="info-box">
        <strong>üéØ Objectif:</strong><br>
        Optimiser les param√®tres du circuit de lixiviation (pH, concentration CN‚Åª, temps, temp√©rature) 
        pour maximiser la r√©cup√©ration d'or en utilisant des algorithmes de r√©gression multivari√©e.
    </div>
    """, unsafe_allow_html=True)
    
    # √âTAPE 1: G√©n√©ration des donn√©es
    st.markdown('<div class="step-header">üìä √âtape 1: G√©n√©ration des Donn√©es Process</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### Param√®tres de G√©n√©ration")
        optim_samples = st.slider("Nombre d'essais", 100, 5000, 600, 100, key="optim_samples")
        optim_variability = st.select_slider(
            "Variabilit√© du minerai",
            options=["Faible", "Moyenne", "√âlev√©e"],
            value="Moyenne",
            key="optim_variability"
        )
        
        if st.button("üé≤ G√©n√©rer les Donn√©es", key="gen_optim"):
            variability_map = {"Faible": 0.6, "Moyenne": 1.0, "√âlev√©e": 1.4}
            v_factor = variability_map[optim_variability]
            
            data = []
            for i in range(optim_samples):
                pH = 9.5 + np.random.random() * 2
                CN = 200 + np.random.random() * 800
                temps = 12 + np.random.random() * 36
                temp = 20 + np.random.random() * 30
                solides = 35 + np.random.random() * 15
                O2 = 4 + np.random.random() * 6
                P80 = 50 + np.random.random() * 100
                
                # Mod√®le de r√©cup√©ration
                recovery = (
                    70 +
                    (pH - 10.5) * 3 +
                    (CN / 600) * 8 +
                    (temps / 30) * 5 -
                    (temp - 35) * 0.3 +
                    (O2 / 7) * 4 -
                    (P80 / 100) * 3 +
                    (np.random.random() - 0.5) * 10 * v_factor
                )
                recovery = max(60, min(98, recovery))
                
                data.append({
                    'pH': round(pH, 2),
                    'CN_ppm': round(CN, 0),
                    'Temps_h': round(temps, 1),
                    'Temperature_C': round(temp, 1),
                    'Solides_%': round(solides, 1),
                    'O2_ppm': round(O2, 1),
                    'P80_um': round(P80, 0),
                    'Recovery_%': round(recovery, 2)
                })
            
            df = pd.DataFrame(data)
            st.session_state.optim_data = df
            st.success(f"‚úÖ {optim_samples} essais g√©n√©r√©s avec succ√®s!")
    
    with col2:
        st.markdown("### Param√®tres Process")
        st.markdown("""
        **Variables contr√¥lables:**
        - üîπ **pH solution** - 9.5 √† 11.5
        - üîπ **[CN‚Åª] (ppm)** - 200 √† 1000 ppm
        - üîπ **Temps s√©jour (h)** - 12 √† 48 heures
        - üîπ **Temp√©rature (¬∞C)** - 20 √† 50¬∞C
        - üîπ **% solides pulpe** - 35 √† 50%
        - üîπ **[O‚ÇÇ] dissous (ppm)** - 4 √† 10 ppm
        - üîπ **Granulom√©trie P80 (Œºm)** - 50 √† 150 Œºm
        
        ‚ûú **Variable cible:** R√©cup√©ration Au (%)
        """)
    
    # Affichage des donn√©es g√©n√©r√©es
    if st.session_state.optim_data is not None:
        st.markdown("### üìä Aper√ßu des Donn√©es G√©n√©r√©es")
        
        col1, col2, col3 = st.columns(3)
        avg_recovery = st.session_state.optim_data['Recovery_%'].mean()
        max_recovery = st.session_state.optim_data['Recovery_%'].max()
        min_recovery = st.session_state.optim_data['Recovery_%'].min()
        
        col1.metric("Moy R√©cup (%)", f"{avg_recovery:.2f}")
        col2.metric("Max R√©cup (%)", f"{max_recovery:.2f}")
        col3.metric("Min R√©cup (%)", f"{min_recovery:.2f}")
        
        st.dataframe(st.session_state.optim_data.head(10), use_container_width=True)
        
        # T√©l√©chargement
        csv = download_data(st.session_state.optim_data, "optimisation_process.csv")
        st.download_button(
            label="üì• T√©l√©charger CSV",
            data=csv,
            file_name="optimisation_process.csv",
            mime="text/csv",
            key="download_optim"
        )
    
    # √âTAPE 2: Configuration du mod√®le
    if st.session_state.optim_data is not None:
        st.markdown('<div class="step-header">‚öôÔ∏è √âtape 2: Configuration du Mod√®le d\'Optimisation</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            optim_algo = st.selectbox(
                "Algorithme d'Optimisation",
                ["Random Forest", "Gradient Boosting", "Neural Network (MLP)"],
                key="optim_algo_select"
            )
            
            algo_info = {
                "Random Forest": "For√™t al√©atoire - Capture interactions complexes",
                "Gradient Boosting": "Gradient Boosting - Tr√®s pr√©cis",
                "Neural Network (MLP)": "R√©seau neuronal - Relations non-lin√©aires"
            }
            st.info(algo_info[optim_algo])
        
        with col2:
            st.markdown("### Param√®tres du Mod√®le")
            
            if optim_algo == "Random Forest":
                col_a, col_b = st.columns(2)
                with col_a:
                    n_estimators_optim = st.number_input("n_estimators", 10, 1000, 300, 10, key="rf_optim_n")
                    st.caption("Plus d'arbres pour capturer interactions")
                with col_b:
                    max_depth_optim = st.number_input("max_depth", 3, 50, 12, key="rf_optim_depth")
                    st.caption("Profondeur pour capturer non-lin√©arit√©s")
                    
            elif optim_algo == "Gradient Boosting":
                col_a, col_b = st.columns(2)
                with col_a:
                    n_estimators_optim = st.number_input("n_estimators", 10, 1000, 200, 10, key="gb_optim_n")
                    st.caption("Nombre d'arbres de boosting")
                with col_b:
                    learning_rate_optim = st.number_input("learning_rate", 0.01, 1.0, 0.1, 0.01, key="gb_optim_lr")
                    st.caption("Taux d'apprentissage")
                    
            else:  # Neural Network
                hidden_layers = st.text_input("hidden_layers (ex: 100,50)", "100,50", key="mlp_hidden")
                st.caption("Architecture r√©seau neuronal")
                learning_rate_mlp = st.number_input("learning_rate", 0.0001, 0.1, 0.001, 0.001, key="mlp_lr")
                st.caption("Taux pour descente de gradient")
                max_iter_mlp = st.number_input("max_iter", 100, 2000, 500, key="mlp_iter")
                st.caption("Nombre max d'√©poques")
        
        # √âTAPE 3: Entra√Ænement et r√©sultats
        st.markdown('<div class="step-header">üìä √âtape 3: R√©sultats et Param√®tres Optimaux</div>', unsafe_allow_html=True)
        
        if st.button("‚ñ∂ Entra√Æner et Optimiser", key="train_optim"):
            with st.spinner("‚è≥ Optimisation en cours..."):
                df = st.session_state.optim_data
                
                # Pr√©paration des donn√©es
                X = df.drop('Recovery_%', axis=1)
                y = df['Recovery_%']
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
                
                # Standardisation
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                
                # Entra√Ænement du mod√®le
                if optim_algo == "Random Forest":
                    model = RandomForestRegressor(
                        n_estimators=n_estimators_optim,
                        max_depth=max_depth_optim,
                        random_state=42
                    )
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    
                elif optim_algo == "Gradient Boosting":
                    model = GradientBoostingRegressor(
                        n_estimators=n_estimators_optim,
                        learning_rate=learning_rate_optim,
                        random_state=42
                    )
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    
                else:  # Neural Network
                    from sklearn.neural_network import MLPRegressor
                    layers = tuple(map(int, hidden_layers.split(',')))
                    model = MLPRegressor(
                        hidden_layer_sizes=layers,
                        learning_rate_init=learning_rate_mlp,
                        max_iter=max_iter_mlp,
                        random_state=42
                    )
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                
                # Calcul des m√©triques
                r2 = r2_score(y_test, y_pred)
                
                # Trouver les param√®tres optimaux (via pr√©diction sur grille)
                from scipy.optimize import differential_evolution
                
                def objective(params):
                    # Transformation des params
                    if optim_algo == "Neural Network":
                        params_scaled = scaler.transform([params])
                        return -model.predict(params_scaled)[0]
                    else:
                        return -model.predict([params])[0]
                
                # Bornes pour l'optimisation
                bounds = [
                    (9.5, 11.5),   # pH
                    (200, 1000),   # CN
                    (12, 48),      # Temps
                    (20, 50),      # Temp√©rature
                    (35, 50),      # Solides
                    (4, 10),       # O2
                    (50, 150)      # P80
                ]
                
                result = differential_evolution(objective, bounds, seed=42, maxiter=100)
                optimal_params = result.x
                optimal_recovery = -result.fun
                
                baseline_recovery = y.mean()
                improvement = ((optimal_recovery - baseline_recovery) / baseline_recovery) * 100
                
                # Affichage des r√©sultats
                st.markdown("### üéØ M√©triques de Performance")
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("R¬≤ Mod√®le", f"{r2:.3f}", "Qualit√© pr√©diction")
                col2.metric("R√©cup. Optimale", f"{optimal_recovery:.2f}%", "R√©cup√©ration Au max")
                col3.metric("R√©cup. Baseline", f"{baseline_recovery:.2f}%", "Avant optimisation")
                col4.metric("Am√©lioration", f"+{improvement:.1f}%", "Gain relatif")
                
                # Param√®tres optimaux
                st.markdown(f"""
                <div class="success-box">
                    <strong>üéØ Param√®tres Optimaux:</strong><br><br>
                    ‚Ä¢ pH: {optimal_params[0]:.2f}<br>
                    ‚Ä¢ [CN‚Åª]: {optimal_params[1]:.0f} ppm<br>
                    ‚Ä¢ Temps: {optimal_params[2]:.1f} h<br>
                    ‚Ä¢ Temp√©rature: {optimal_params[3]:.1f}¬∞C<br>
                    ‚Ä¢ % Solides: {optimal_params[4]:.1f}%<br>
                    ‚Ä¢ [O‚ÇÇ]: {optimal_params[5]:.1f} ppm<br>
                    ‚Ä¢ P80: {optimal_params[6]:.0f} Œºm<br><br>
                    <strong>Gain: +{improvement:.1f}%</strong>
                </div>
                """, unsafe_allow_html=True)
                
                # Importance des features
                if optim_algo in ["Random Forest", "Gradient Boosting"]:
                    st.markdown("### üìä Importance des Param√®tres")
                    
                    feature_importance = pd.DataFrame({
                        'Param√®tre': X.columns,
                        'Importance': model.feature_importances_
                    }).sort_values('Importance', ascending=True)
                    
                    fig = px.bar(
                        feature_importance,
                        x='Importance',
                        y='Param√®tre',
                        orientation='h',
                        title="Importance des Param√®tres Process"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # Graphique de surface 3D pour pH vs CN vs Recovery
                st.markdown("### üìä Surface de R√©ponse: pH vs CN")
                
                # Cr√©er une grille pour pH et CN
                pH_range = np.linspace(9.5, 11.5, 30)
                CN_range = np.linspace(200, 1000, 30)
                pH_grid, CN_grid = np.meshgrid(pH_range, CN_range)
                
                # Fixer les autres param√®tres √† leurs valeurs optimales
                recovery_grid = np.zeros_like(pH_grid)
                for i in range(pH_grid.shape[0]):
                    for j in range(pH_grid.shape[1]):
                        params = [
                            pH_grid[i, j],
                            CN_grid[i, j],
                            optimal_params[2],
                            optimal_params[3],
                            optimal_params[4],
                            optimal_params[5],
                            optimal_params[6]
                        ]
                        if optim_algo == "Neural Network":
                            params_scaled = scaler.transform([params])
                            recovery_grid[i, j] = model.predict(params_scaled)[0]
                        else:
                            recovery_grid[i, j] = model.predict([params])[0]
                
                fig = go.Figure(data=[go.Surface(
                    x=pH_range,
                    y=CN_range,
                    z=recovery_grid,
                    colorscale='Viridis'
                )])
                
                fig.update_layout(
                    title='Surface de R√©ponse: R√©cup√©ration vs pH et CN',
                    scene=dict(
                        xaxis_title='pH',
                        yaxis_title='CN (ppm)',
                        zaxis_title='R√©cup√©ration (%)'
                    ),
                    height=600
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Code Python √©quivalent
                st.markdown("### üíª Code Python √âquivalent")
                
                if optim_algo == "Random Forest":
                    params = f"n_estimators={n_estimators_optim}, max_depth={max_depth_optim}"
                    model_name = "RandomForestRegressor"
                elif optim_algo == "Gradient Boosting":
                    params = f"n_estimators={n_estimators_optim}, learning_rate={learning_rate_optim}"
                    model_name = "GradientBoostingRegressor"
                else:
                    params = f"hidden_layer_sizes={hidden_layers}, learning_rate_init={learning_rate_mlp}, max_iter={max_iter_mlp}"
                    model_name = "MLPRegressor"
                
                code = f"""
from sklearn.ensemble import {model_name}
from scipy.optimize import differential_evolution

model = {model_name}({params})
model.fit(X_train, y_train)

def objective(params):
    return -model.predict([params])[0]

bounds = [(9.5, 11.5), (200, 1000), (12, 48), (20, 50), (35, 50), (4, 10), (50, 150)]
result = differential_evolution(objective, bounds)

print(f"R√©cup√©ration optimale: {optimal_recovery:.2f}%")
print(f"Param√®tres: pH={optimal_params[0]:.2f}, CN={optimal_params[1]:.0f}")
"""
                st.code(code, language="python")

# ======================= ONGLET 4: MAINTENANCE ======================= #
with tab4:
    st.markdown("## Maintenance Pr√©dictive des √âquipements")
    
    st.markdown("""
    <div class="info-box">
        <strong>üéØ Objectif:</strong><br>
        Pr√©dire les pannes d'√©quipements critiques (broyeurs, pompes, convoyeurs) √† partir de donn√©es 
        de capteurs IoT pour anticiper la maintenance et minimiser les arr√™ts non planifi√©s.
    </div>
    """, unsafe_allow_html=True)
    
    # √âTAPE 1: G√©n√©ration des donn√©es
    st.markdown('<div class="step-header">üìä √âtape 1: G√©n√©ration des Donn√©es Capteurs</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### Param√®tres de G√©n√©ration")
        maint_samples = st.slider("Nombre de mesures", 100, 5000, 1200, 100, key="maint_samples")
        maint_failure = st.slider("Taux de pannes (%)", 5, 30, 15, 5, key="maint_failure")
        
        if st.button("üé≤ G√©n√©rer les Donn√©es", key="gen_maint"):
            n_failures = int(maint_samples * maint_failure / 100)
            n_normal = maint_samples - n_failures
            
            data = []
            
            # Donn√©es de panne
            for i in range(n_failures):
                vibration = 8 + np.random.random() * 12
                temperature = 75 + np.random.random() * 25
                courant = 180 + np.random.random() * 70
                pression_huile = 1.5 + np.random.random() * 2
                vitesse = 600 + np.random.random() * 400
                bruit = 95 + np.random.random() * 20
                heures = 4000 + np.random.random() * 6000
                
                data.append({
                    'Vibration_mm_s': round(vibration, 2),
                    'Temperature_C': round(temperature, 1),
                    'Courant_A': round(courant, 1),
                    'Pression_huile_bar': round(pression_huile, 2),
                    'Vitesse_RPM': round(vitesse, 0),
                    'Bruit_dB': round(bruit, 1),
                    'Heures_fonct': round(heures, 0),
                    'Etat': 1  # Panne
                })
            
            # Donn√©es normales
            for i in range(n_normal):
                vibration = 2 + np.random.random() * 4
                temperature = 50 + np.random.random() * 15
                courant = 120 + np.random.random() * 40
                pression_huile = 4 + np.random.random() * 2
                vitesse = 900 + np.random.random() * 200
                bruit = 75 + np.random.random() * 12
                heures = 500 + np.random.random() * 3000
                
                data.append({
                    'Vibration_mm_s': round(vibration, 2),
                    'Temperature_C': round(temperature, 1),
                    'Courant_A': round(courant, 1),
                    'Pression_huile_bar': round(pression_huile, 2),
                    'Vitesse_RPM': round(vitesse, 0),
                    'Bruit_dB': round(bruit, 1),
                    'Heures_fonct': round(heures, 0),
                    'Etat': 0  # Normal
                })
            
            df = pd.DataFrame(data)
            df = df.sample(frac=1).reset_index(drop=True)
            st.session_state.maint_data = df
            st.success(f"‚úÖ {maint_samples} mesures g√©n√©r√©es avec succ√®s!")
    
    with col2:
        st.markdown("### Signaux Capteurs")
        st.markdown("""
        **Variables mesur√©es:**
        - üîπ **Vibration (mm/s)** - Acc√©l√©rom√®tres
        - üîπ **Temp√©rature (¬∞C)** - Thermocouples
        - üîπ **Courant moteur (A)** - Charge √©lectrique
        - üîπ **Pression huile (bar)** - Syst√®me lubrifiant
        - üîπ **Vitesse rotation (RPM)** - Encodeur
        - üîπ **Niveau bruit (dB)** - Acoustique
        - üîπ **Heures fonctionnement** - Temps cumul√©
        
        ‚ûú **√âtat (0=Normal, 1=Panne)** - Variable cible
        """)
    
    # Affichage des donn√©es g√©n√©r√©es
    if st.session_state.maint_data is not None:
        st.markdown("### üìä Aper√ßu des Donn√©es G√©n√©r√©es")
        
        col1, col2, col3 = st.columns(3)
        total_samples = len(st.session_state.maint_data)
        pannes = len(st.session_state.maint_data[st.session_state.maint_data['Etat'] == 1])
        normal = total_samples - pannes
        
        col1.metric("Total Mesures", total_samples)
        col2.metric("Pannes", pannes)
        col3.metric("Normal", normal)
        
        # Afficher avec labels textuels
        df_display = st.session_state.maint_data.copy()
        df_display['Etat_Text'] = df_display['Etat'].map({0: 'Normal', 1: 'Panne'})
        st.dataframe(df_display.head(10), use_container_width=True)
        
        # T√©l√©chargement
        csv = download_data(st.session_state.maint_data, "maintenance_predictive.csv")
        st.download_button(
            label="üì• T√©l√©charger CSV",
            data=csv,
            file_name="maintenance_predictive.csv",
            mime="text/csv",
            key="download_maint"
        )
    
    # √âTAPE 2: Configuration du mod√®le
    if st.session_state.maint_data is not None:
        st.markdown('<div class="step-header">‚öôÔ∏è √âtape 2: Configuration du Mod√®le Pr√©dictif</div>', unsafe_allow_html=True)
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            maint_algo = st.selectbox(
                "Algorithme de Pr√©diction",
                ["Random Forest", "XGBoost", "Logistic Regression"],
                key="maint_algo_select"
            )
            
            algo_info = {
                "Random Forest": "For√™t al√©atoire - √âquilibr√© pr√©cision/rappel",
                "XGBoost": "XGBoost - Excellent pour d√©s√©quilibre classes",
                "Logistic Regression": "R√©gression logistique - Probabilit√©s interpr√©tables"
            }
            st.info(algo_info[maint_algo])
        
        with col2:
            st.markdown("### Param√®tres du Mod√®le")
            
            if maint_algo == "Random Forest":
                col_a, col_b = st.columns(2)
                with col_a:
                    n_estimators_maint = st.number_input("n_estimators", 10, 1000, 200, 10, key="rf_maint_n")
                    st.caption("Plus d'arbres = pr√©dictions robustes")
                with col_b:
                    max_depth_maint = st.number_input("max_depth", 3, 50, 15, key="rf_maint_depth")
                    st.caption("Profondeur pour interactions")
                class_weight = st.selectbox("class_weight", ["balanced", "none"], key="rf_class_weight")
                st.caption("Balanced compense d√©s√©quilibre. CRUCIAL!")
                
            elif maint_algo == "XGBoost":
                col_a, col_b = st.columns(2)
                with col_a:
                    n_estimators_maint = st.number_input("n_estimators", 10, 1000, 150, 10, key="xgb_maint_n")
                    st.caption("Arbres de boosting s√©quentiels")
                with col_b:
                    learning_rate_maint = st.number_input("learning_rate", 0.01, 1.0, 0.1, 0.01, key="xgb_maint_lr")
                    st.caption("Taux d'apprentissage")
                scale_pos_weight = st.number_input("scale_pos_weight", 1, 20, 5, key="xgb_scale")
                st.caption("Poids pour pannes. Plus √©lev√© = sensibilit√©")
                
            else:  # Logistic Regression
                col_a, col_b = st.columns(2)
                with col_a:
                    C_maint = st.number_input("C (R√©gularisation)", 0.01, 100.0, 1.0, 0.1, key="lr_maint_c")
                    st.caption("Inverse r√©gularisation")
                with col_b:
                    class_weight = st.selectbox("class_weight", ["balanced", "none"], key="lr_class_weight")
                    st.caption("√âquilibrer poids classes")
        
        # √âTAPE 3: Entra√Ænement et r√©sultats
        st.markdown('<div class="step-header">üìä √âtape 3: R√©sultats et Alertes Pr√©dictives</div>', unsafe_allow_html=True)
        
        if st.button("‚ñ∂ Entra√Æner le Mod√®le", key="train_maint"):
            with st.spinner("‚è≥ Entra√Ænement en cours..."):
                df = st.session_state.maint_data
                
                # Pr√©paration des donn√©es
                X = df.drop('Etat', axis=1)
                y = df['Etat']
                
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, stratify=y, random_state=42
                )
                
                # Standardisation
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                
                # Entra√Ænement du mod√®le
                if maint_algo == "Random Forest":
                    cw = 'balanced' if class_weight == 'balanced' else None
                    model = RandomForestClassifier(
                        n_estimators=n_estimators_maint,
                        max_depth=max_depth_maint,
                        class_weight=cw,
                        random_state=42
                    )
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    
                elif maint_algo == "XGBoost":
                    from xgboost import XGBClassifier
                    model = XGBClassifier(
                        n_estimators=n_estimators_maint,
                        learning_rate=learning_rate_maint,
                        scale_pos_weight=scale_pos_weight,
                        random_state=42
                    )
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    
                else:  # Logistic Regression
                    cw = 'balanced' if class_weight == 'balanced' else None
                    model = LogisticRegression(C=C_maint, class_weight=cw, max_iter=1000, random_state=42)
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                
                # Calcul des m√©triques
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred)
                recall = recall_score(y_test, y_pred)
                f1 = f1_score(y_test, y_pred)
                cm = confusion_matrix(y_test, y_pred)
                
                # Affichage des r√©sultats
                st.markdown("### üéØ M√©triques de Performance")
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("Accuracy", f"{accuracy:.3f}", "Pr√©cision globale")
                col2.metric("Recall (Pannes)", f"{recall:.3f}", f"{recall*100:.1f}% d√©tect√©es")
                col3.metric("Precision", f"{precision:.3f}", "Fiabilit√© alertes")
                col4.metric("F1-Score", f"{f1:.3f}", "Score √©quilibr√©")
                
                # Interpr√©tation
                st.markdown(f"""
                <div class="warning-box">
                    <strong>‚ö†Ô∏è Interpr√©tation:</strong><br>
                    ‚Ä¢ <strong>Recall = {recall*100:.1f}%:</strong> D√©tecte {recall*100:.1f}% des pannes<br>
                    ‚Ä¢ <strong>Precision = {precision*100:.1f}%:</strong> {precision*100:.1f}% des alertes justifi√©es<br>
                    ‚Ä¢ <strong>Impact:</strong> Maintenance proactive et r√©duction temps d'arr√™t
                </div>
                """, unsafe_allow_html=True)
                
                # Matrice de confusion
                st.markdown("### üìä Matrice de Confusion")
                
                fig = go.Figure(data=go.Heatmap(
                    z=cm,
                    x=['Normal', 'Panne'],
                    y=['Normal', 'Panne'],
                    text=cm,
                    texttemplate="%{text}",
                    textfont={"size": 20},
                    colorscale='RdYlGn_r'
                ))
                fig.update_layout(
                    title="Matrice de Confusion",
                    xaxis_title="Pr√©diction",
                    yaxis_title="R√©alit√©",
                    height=400
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Importance des features
                if maint_algo in ["Random Forest", "XGBoost"]:
                    st.markdown("### üìä Importance des Signaux Capteurs")
                    
                    feature_importance = pd.DataFrame({
                        'Signal': X.columns,
                        'Importance': model.feature_importances_
                    }).sort_values('Importance', ascending=True)
                    
                    # Ajouter interpr√©tation
                    interpretations = {
                        'Vibration_mm_s': 'Indicateur principal usure',
                        'Temperature_C': 'Surchauffe roulements',
                        'Heures_fonct': 'Fatigue mat√©riaux',
                        'Courant_A': 'Charge anormale',
                        'Pression_huile_bar': 'Probl√®me lubrification',
                        'Vitesse_RPM': 'D√©salignement',
                        'Bruit_dB': 'Anomalie acoustique'
                    }
                    
                    fig = px.bar(
                        feature_importance,
                        x='Importance',
                        y='Signal',
                        orientation='h',
                        title="Importance Relative des Signaux"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Tableau d'interpr√©tation
                    st.markdown("### üîç Interpr√©tation des Signaux")
                    
                    interp_df = feature_importance.copy()
                    interp_df['Interpr√©tation'] = interp_df['Signal'].map(interpretations)
                    st.dataframe(interp_df[['Signal', 'Importance', 'Interpr√©tation']], use_container_width=True)
                
                # Code Python √©quivalent
                st.markdown("### üíª Code Python √âquivalent")
                
                if maint_algo == "Random Forest":
                    cw_str = "'balanced'" if class_weight == 'balanced' else "None"
                    params = f"n_estimators={n_estimators_maint}, max_depth={max_depth_maint}, class_weight={cw_str}"
                    model_name = "RandomForestClassifier"
                elif maint_algo == "XGBoost":
                    params = f"n_estimators={n_estimators_maint}, learning_rate={learning_rate_maint}, scale_pos_weight={scale_pos_weight}"
                    model_name = "XGBClassifier"
                else:
                    cw_str = "'balanced'" if class_weight == 'balanced' else "None"
                    params = f"C={C_maint}, class_weight={cw_str}"
                    model_name = "LogisticRegression"
                
                code = f"""
from sklearn.ensemble import {model_name}

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)

model = {model_name}({params})
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(f"Recall: {recall:.3f}")
print(f"Accuracy: {accuracy:.3f}")
"""
                st.code(code, language="python")

# Footer
st.markdown("""
<div class="footer">
    <p style="font-weight: 600;">¬© 2025 Application ML Mining - Didier Ouedraogo, P.Geo</p>
    <p style="color: #9ca3af;">Simulateur p√©dagogique pour l'industrie mini√®re | Donn√©es simul√©es √† des fins didactiques</p>
</div>
""", unsafe_allow_html=True)